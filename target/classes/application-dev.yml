spring:
  data:
    mongodb:
      uri: mongodb+srv://tanmaydevikar99:AKCzxqY1rdNIq52S@cluster0.xhvsyma.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0
      database: journaldb
      auto-index-creation: true

  redis:
    host: redis-16446.c84.us-east-1-2.ec2.redns.redis-cloud.com   #For redis cloud connection
    port: 16446   #For redis cloud connection
    password: UzKzdne86pSqbJ35cEbxZW1U9GNQ9Ozi      #For redis cloud connection
#    host: localhost     #For local connection
#    port: 6379   #For local connection


  mail:
    host: smtp.gmail.com  #The mail provider provides the host. For gmail it is smtp.gmail.com, for yahoo it is smtp.mail.yahoo.com, for outlook it is smtp.office365.com.
    port: 587  #For unencrypted things, port is 25. But as we are using encryption (starttls.enable: true), the port is 587
    username: tanmaydevikar99@gmail.com
    password: vbvz lude ysru dhdr
    properties:
      mail:
        smtp:
          auth: true  #Means that out application needs a username and a password for the authorization
          starttls:
            enable: true

  kafka:
    bootstrap-servers: pkc-921jm.us-east-2.aws.confluent.cloud:9092   #If running on localhost then 'localhost:port'. If multiple brokers are running, then comma seperated entitites.
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer  #key and value serializer, same as redis.
    consumer:
      group-id: weekly-sentiment-group
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer   #key and value deserializer, same as redis.
      properties:
        spring:
          json:
            trusted:
              packages: net.engineeringdigest.journalApp.*  #When the consumer will consume, we need to tell which are the trusted packages. Means, upcoming data from which packages are safe to consume.
                        #net.engineeringdigest.journalApp.*    for all.
                        #SSL means the data we are transferring will be in encrypted form.
    properties:
      security:
        protocol: SASL_SSL  #SASL: Simple Authentication and Security Level. SASL is used for authentication.
      sasl:
        mechanism: PLAIN   #Plain mechanism for authentication, means username and password will be in simple text.
        jaas:    #Java Authentication and Authorization service
          config: org.apache.kafka.common.security.plain.PlainLoginModule required username='TZMNFG3Y7M35243Q' password='STE8Ol1e7r1kec7Q9puUiL4idGBSHncKPZw9a+HicwzEKam5V/jXkj3vJUnnB++l';
      session:
        timeout:
          ms: 45000    #The consumer continuously sends heart beats, i.e., signals to the broker. If the consumer doesn't send the heart beat for some specific time (in our case, we have set 4500ms, i.e., 45 secs), the broker will consider that particular consumer as dead, and will assign the partition to some other consumer.

server:
  port: 8080
  servlet:
    context-path: /journal

weather:
  api:
    key: a689032e0e3b4aef8da82548241506